import google.generativeai as genai
import speech_recognition as sr
import pyttsx3
import webbrowser
import os
import datetime
import cv2
import pyautogui
import time
import smtplib
import numpy as np
from keras.models import load_model

# Configure Google Generative AI API key
genai.configure(api_key="AIzaSyBKzRSFkSOl0uJGCWMA9COw7NhlhHPnVgo")
model = genai.GenerativeModel("gemini-pro")

# Initialize the speech recognition recognizer outside the loop
recognizer = sr.Recognizer()

# Initialize the text-to-speech engine outside the loop
engine = pyttsx3.init()

# Load the face emotion detection model
emotion_model = load_model('C:/Users/saite/Downloads/model_file_30epochs.h5')
face_cascade_path = 'C:/Users/saite/Downloads/haarcascade_frontalface_default.xml'
face_detect = cv2.CascadeClassifier(face_cascade_path)

labels_dict = {0: 'Angry', 1: 'Disgust', 2: 'Fear', 3: 'Happy', 4: 'Neutral', 5: 'Sad', 6: 'Surprise'}

def say(text):
    engine.say(text)
    engine.runAndWait()

def takeCommand():
    with sr.Microphone() as source:
        recognizer.pause_threshold = 1
        print("Listening...")
        try:
            audio = recognizer.listen(source, timeout=10)
            print("Recognizing...")
            text = recognizer.recognize_google(audio, language="en-in")
            print(f"User said: {text}")
            return text
        except sr.UnknownValueError:
            print("Sorry, I did not understand from Tej A.I.")
            return ""
        except sr.RequestError as e:
            print(f"Request failed; {e}")
            return ""

# Existing functions (e.g., wishme, detect_objects, send_mail, play_youtube_video, etc.)
        
def writeNotepad(content):
    pyautogui.typewrite(content)

def saveNotepad():
    pyautogui.hotkey('ctrl', 's')
    time.sleep(0.5)
    pyautogui.press('enter')

# Function to greet based on the time of day
def wishme():
    hour = datetime.datetime.now().hour
    if 0 <= hour < 12:
        say("Good Morning sir")
    elif 12 <= hour < 18:
        say("Good Afternoon sir")
    else:
        say("Good Evening sir")

    say("Hello, I am Tej A.I")

def detect_objects_with_info():
    config_file = "C:\\Users\\saite\\Downloads\\ssd_mobilenet_v3_large_coco_2020_01_14 (2).pbtxt"
    frozen_model = "C:\\Users\\saite\\Downloads\\frozen_inference_graph (1).pb"
    labels_file = "C:\\Users\\saite\\Downloads\\coco (1).names"

    net = cv2.dnn_DetectionModel(frozen_model, config_file)

    with open(labels_file, 'rt') as f:
        labels = f.read().rstrip('\n').split('\n')

    net.setInputSize(320, 320)
    net.setInputScale(1.0 / 127.5)
    net.setInputMean((127.5, 127.5, 127.5))
    net.setInputSwapRB(True)

    cap = cv2.VideoCapture(0)

    while True:
        ret, frame = cap.read()
        if not ret:
            break

        classes, confidences, boxes = net.detect(frame, confThreshold=0.5)

        detected_objects = []

        for classId, confidence, box in zip(classes.flatten(), confidences.flatten(), boxes):
            label = labels[classId - 1]
            confidence_percent = f'{confidence * 100:.2f}%'
            object_info_prompt = f"Tell me about the {label}"
            response = model.generate_content(contents=[object_info_prompt])

            # Check if the response is valid and has safety_ratings attribute
            if hasattr(response, 'safety_ratings') and response.safety_ratings and response.safety_ratings[0].confidence < 0.5:
                # If the response is blocked or not confident enough, handle it accordingly
                detected_objects.append(f"{label} with {confidence_percent} confidence. [Blocked or low confidence]")
            else:
                object_info = response.text[:100]  # Limit the response to 100 characters
                detected_objects.append(f"{label} with {confidence_percent} confidence. {object_info}")

            cv2.rectangle(frame, box, color=(0, 255, 0), thickness=2)
            cv2.putText(frame, f'{label}: {confidence_percent}', (box[0], box[1] - 10),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)

        if detected_objects:
            # Combine the spoken information
            combined_info = ", ".join(detected_objects)
            
            # Display the spoken information on the frame
            cv2.putText(frame, f'Spoken Output: {combined_info}', (10, 20),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)
            
            # Display the detected objects
            cv2.putText(frame, f'Detected Objects: {", ".join(labels)}', (10, 40),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)

            # Display the response generated by Generative AI
            if hasattr(response, 'safety_ratings') and response.safety_ratings and response.safety_ratings[0].confidence < 0.5:
                cv2.putText(frame, f'Generative AI Response: [Blocked or low confidence]', (10, 60),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)
            else:
                cv2.putText(frame, f'Generative AI Response: {response.text}', (10, 60),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)

            # Speak the detected objects information
            say(f"I detected {len(detected_objects)} objects: {combined_info}")

        cv2.imshow('Object Detection with Info', frame)

        if cv2.waitKey(1) == 27:  # Press 'Esc' to exit
            break

    cap.release()
    cv2.destroyAllWindows()
def send_mail():
    say("Sure, I will help you send an email. Please provide details.")
    receiver_email = "saitej13sai@gmail.com"
    say("Please say the subject of the email.")
    subject = takeCommand()

    # Speech recognition for message
    say("Please say the message of the email.")
    message = takeCommand()

    email = "tejteamai@gmail.com"
    text = f"Subject:{subject}\n\n{message}"

    server = smtplib.SMTP("smtp.gmail.com", 587)
    server.starttls()

    server.login(email, "epii ffwv ndiw eaku")  # Replace with your email password

    server.sendmail(email, receiver_email, text)

    say(f"Email has been sent to {receiver_email}")

def play_youtube_video(query):
    url = f"https://www.youtube.com/results?search_query={query}"
    webbrowser.open(url)

def get_emotion_message(emotion):
    messages = {
        'Angry': "I sense some anger. Take a deep breath and stay calm.",
        'Disgust': "Feeling disgusted? Try to focus on positive thoughts.",
        'Fear': "If you're feeling scared, remember that you're stronger than you think.",
        'Happy': "You look happy! Keep that smile on your face!",
        'Neutral': "A neutral expression? Stay positive and enjoy the moment.",
        'Sad': "If you're feeling sad, know that I'm here for you. Try to find joy in small things.",
        'Surprise': "Surprised? Life is full of unexpected moments. Embrace them!"
    }
    return messages.get(emotion, "I sense an emotion, but I'm not sure how to respond.")


def detect_face_emotion():
    video = cv2.VideoCapture(0)

    while True:
        try:
            ret, frame = video.read()

            if not ret:
                print("Error reading from the camera.")
                break

            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            faces = face_detect.detectMultiScale(gray, 1.3, 3)

            for x, y, w, h in faces:
                sub_face_img = gray[y:y + h, x:x + w]
                resized = cv2.resize(sub_face_img, (48, 48))
                normalize = resized / 255.0
                reshaped = np.reshape(normalize, (1, 48, 48, 1))
                result = emotion_model.predict(reshaped)
                label = np.argmax(result, axis=1)[0]

                # Speak the detected emotion and provide personalized messages
                emotion_text = labels_dict[label]
                emotion_message = get_emotion_message(emotion_text)

                engine.say(f"The detected emotion is {emotion_text}. {emotion_message}")
                engine.runAndWait()

                cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 0, 255), 1)
                cv2.rectangle(frame, (x, y), (x + w, y + h), (50, 50, 255), 2)
                cv2.rectangle(frame, (x, y - 40), (x + w, y), (50, 50, 255), -1)
                cv2.putText(frame, emotion_text, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)

            cv2.imshow("Face Emotion Detection", frame)
            k = cv2.waitKey(1)
            if k == ord('q'):
                break

        except Exception as e:
            print(f"An error occurred: {str(e)}")
            break

    # Release the video capture object
    video.release()

    # Destroy all OpenCV windows
    cv2.destroyAllWindows()

if __name__ == '__main__':
    print("TEJ AI")
    wishme()  # Greet the user
    while True:
        print("Listening")
        text = takeCommand()
        command_matched = False

        # Add Generative AI response for every user command
        prompt = text
        response = model.generate_content(contents=[prompt])
        answer = response.text

        short_answer = answer[:100]

        print(f"TEJ AI Response: {short_answer}...")
        say(short_answer)
        command_matched = True

        # Existing commands (e.g., open gmail, open file manager, detect object, send mail, etc.)
        
        if "open gmail" in text.lower():
            say("Opening Gmail...")
            webbrowser.open("https://mail.google.com/")
            command_matched = True

        elif "open file manager" in text.lower():
            say("Opening File Manager...")
            os.startfile("explorer.exe")
            command_matched = True

        elif "open browser" in text.lower():
            say("Opening Browser...")
            webbrowser.open("https://www.google.com/")
            command_matched = True

        elif "open notepad" in text.lower():
            say("Opening Notepad...")
            os.startfile("notepad.exe")
            command_matched = True
            say("Please provide the important points.")
            points_text = takeCommand()
            writeNotepad(points_text)
            command_matched = True

        elif "save it" in text.lower():
            say("Saving the content in Notepad...")
            saveNotepad()
            command_matched = True

        if "detect object" in text.lower():
           say("Detecting objects and providing information, Sir...")
           detect_objects_with_info()
           
           command_matched = True

        if "play youtube video" in text.lower():
            say("Sure, what video would you like to watch?")
            video_query = takeCommand()
            play_youtube_video(video_query)
            command_matched = True

        if "send mail" in text.lower():
            send_mail()
            command_matched = True

        for site in [["youtube", "https://youtube.com"], ["wikipedia", "https://www.wikipedia.org"], ["google", "https://www.google.com"]]:
            if f"open {site[0]}".lower() in text.lower():
                say(f"Opening {site[0]} sir...")
                webbrowser.open(site[1])
                command_matched = True
                break

        if "open music" in text.lower():
            musicPath = r"C:\Users\saite\perfect-beauty-191271.mp3"
            os.startfile(musicPath)
            command_matched = True

        if "the time" in text.lower():
            strfTime = datetime.datetime.now().strftime("%H:%M:%S")
            say(f"sir the time is {strfTime}")
            command_matched = True

        if "open camera" in text.lower():
            cap = cv2.VideoCapture(0)
            while True:
                ret, frame = cap.read()
                cv2.imshow('Camera', frame)
                if cv2.waitKey(1) & 0xFF == ord('q'):
                    break
            cap.release()
            cv2.destroyAllWindows()
            command_matched = True

        # Your existing commands
        if "good morning" in text.lower():
            wishme()
            command_matched = True

        if "good afternoon" in text.lower():
            wishme()
            command_matched = True

        if "good evening" in text.lower():
            wishme()
            command_matched = True

        # ... (existing commands)

        if "exit" in text.lower():
            say("Exiting the program. Goodbye!")
            break

        # Windows Commands...
        # ... (existing commands)

        elif not command_matched:
            say("Sorry, I don't understand that command.")

        # Windows Commands ---->   
        if "shutdown" in text:
            say("Okay, shutting down the computer in 5 seconds....")
            os.system("shutdown /s /t 5 /c goodbye")
            command_matched = True

        if "restart" in text:
            say("Okay, restarting the computer in 5 seconds")
            os.system("shutdown /r /t 5")
            command_matched = True

        if "log out" in text:
            say("Okay, logging out....")
            os.system("shutdown /l")

            command_matched = True

        if "close" in text: 
            pyautogui.hotkey('alt', 'f4')
            command_matched = True

        if "disconnect wifi" in text:
            os.system("netsh wlan disconnect")
            say("WiFi disconnected")
            command_matched = True


        if "detect face" in text.lower():
            say("Detecting face emotions through the camera, Sir...")
            detect_face_emotion()
            command_matched = True
            
        elif not command_matched:
            say("Sorry, I don't understand that command.")
       
